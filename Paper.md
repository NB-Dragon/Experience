# 1 INTRODUCTION
  Selection and compositing are at the core of the image editing process. For instance, local adjustments often start with a selection, and combining elements from different images is a powerful way to produce new content. But creating an accurate selection is a tedious task especially when fuzzy boundaries and transparency are involved. Tools such as the magnetic lasso and the magic wand exist to assist users but they only exploit low-level cues and heavily rely on the usersâ€™ skills and interpretation of the image content to produce good results. Furthermore, they only produce binary selections that need further refinement to account for soft boundaries like the silhouette of a furry dog. Matting tools also exist to help users with this task but they only add to the tedium of the entire editing process.
  An accurate pre-segmentation of the image can speed up the editing process by providing an intermediate image representation if it satisfies several criteria. First of all, such a segmentation should provide distinct segments of the image, while also representing the soft transitions between them accurately. In order to allow targeted edits, each segment should be limited to the extent of a semantically meaningful region in the image, e.g., it should not extend across the boundary between two objects. Finally, the segmentation should be done fully automatically not to add a point of interaction or require expertise from the artist. The previous approaches for semantic segmentation, image matting, or soft color segmentation fail to satisfy at least one of these qualities. In this paper, we introduce semantic soft segmentation, a fully automatic decomposition of an input image into a set of layers that cover scene objects, separated by soft transitions.
  We approach the semantic soft segmentation problem from a spectral decomposition angle. We combine the texture and color information from the input image together with high-level semantic cues that we generate using a convolutional neural network trained for scene analysis. We design a graph structure that reveals the semantic objects as well as the soft transitions between them in the eigenvectors of the corresponding Laplacian matrix. We introduce a spatially varying model of layer sparsity that generates high-quality layers from the eigenvectors that can be utilized for image editing.
  We demonstrate that our algorithm successfully decomposes images into a small number of layers that compactly and accurately represent the scene objects as shown in Figure 1. We later show that our algorithm can successfully process images that are challenging for other techniques and we provide examples of editing operations such as local color adjustment or background replacement that benefit from our layer representation.
# 2 RELATED WORK
  Soft segmentation. Soft segmentation is decomposing an image into two or more segments where each pixel may belong partially to more than one segment. The layer contents change depending on the specific goal of the corresponding method. For instance, soft color segmentation methods extract soft layers of homogeneous colors using global optimization [Singaraju and Vidal 2011; Tai et al. 2007; Tan et al. 2016] or per-pixel color unmixing [Aksoy et al. 2016, 2017b]. While soft color segments are shown to be useful for several image editing applications such as image recoloring, their content typically does not respect object boundaries, not allowing targeted edits. To generate spatially connected soft segments, Singaraju and Vidal [2011] start from a set of user-defined regions and solve two-layer soft segmentation problems multiple times to generate multiple layers. Levin et al. [2008b], on the other hand, propose spectral matting, estimating a set of spatially connected soft segments automatically via spectral decomposition. Both Singaraju and Vidal [2011] and Levin et al. [2008b] construct their algorithms around the matting Laplacian [Levin et al. 2008a], which provides a powerful representation for local soft transitions in the image. We also make use of the matting Laplacian and spectral decomposition, following ideas from spectral matting. However, unlike previous work, we construct a graph that fuses higher-level information coming from a deep network with the local texture information in order to generate soft segments that correspond to semantically meaningful regions in the image.
  Natural image matting. Natural image matting is the estimation of per-pixel opacities of a user-defined foreground region. The typical input to natural matting algorithms is a trimap, which defines the opaque foreground, the transparent background, and the unknownopacity regions. While there are different approaches to this problem all of which make use of the color characteristics of the defined foreground and background regions, the most closely-related approaches to ours are categorized as affinity-based methods. The affinity-based methods, such as closed-form matting [Levin et al. 2008a], KNN matting [Chen et al. 2013], and information-flow matting [Aksoy et al. 2017a], define inter-pixel affinities to construct a graph that reflects the opacity transitions in the image. In contrary to natural image matting methods, we rely on automatically-generated semantic features in defining our soft segments instead of a trimap, and generate multiple soft segments rather than foreground segmentation. Although they appear similar, natural matting and soft segmentation have fundamental differences. Natural matting, with a trimap as input, becomes the problem of foreground and background color modeling, may it be through selection of color samples or propagation of color information. Meanwhile, soft segmentation focuses on detecting soft transitions that best serve the target application, in our case the ones corresponding to semantic boundaries.
  Targeted edit propagation. Several image editing methods rely on user-defined sparse edits on the image and propagate them to the whole image. ScribbleBoost [Li et al. 2008] proposed a pipeline where they classify the objects specified by the user scribbles to allow edits targeting specific object classes in the image, and DeepProp [Endo et al. 2016] utilized a deep network to propagate class-dependent color edits. Eynard et al. [2014] constructs a graph and, parallel to our method, analyze the eigendecomposition of the corresponding Laplacian matrix to create coherent recoloring results. An and Pellacini [2008] and Chen et al. [2012] also define inter-pixel affinities and make use of the properties of the Laplacian matrices to solve for plausible propagations of the user-defined edits. While our results can also be used for targeted edits, rather than using edits defined a priori, we directly decompose the image into soft segments and let the artist use them as an intermediate image representation in various scenarios and using external image editing tools.
  Semantic segmentation. Semantic segmentation has improved significantly with the introduction of deep neural networks. While a detailed report on semantic segmentation is beyond our scope, state-of-the-art in semantic segmentation include works on scene parsing by Zhao et al. [2017], instance segmentation methods by He et al. [2017] and Fathi et al. [2017], and work by Bertasius et al. [2016] which enhances semantic segmentation with color boundary cues. We also make use of a deep network for semantic features, but our soft segmentation method is class-agnostic, i.e. we are interested in an accurate segmentation of the image respecting semantic boundaries, but we do not aim to do classification or detection of a selected set of classes. Others also make use of class-agnostic semantic information to improve performance in video deblurring [Ren et al. 2017] or cinemagraph generation [Oh et al. 2017].
