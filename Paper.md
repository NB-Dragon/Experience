# 1 INTRODUCTION
&ensp;&ensp;Selection and compositing are at the core of the image editing process. For instance, local adjustments often start with a selection, and combining elements from different images is a powerful way to produce new content. But creating an accurate selection is a tedious task especially when fuzzy boundaries and transparency are involved. Tools such as the magnetic lasso and the magic wand exist to assist users but they only exploit low-level cues and heavily rely on the users’ skills and interpretation of the image content to produce good results. Furthermore, they only produce binary selections that need further refinement to account for soft boundaries like the silhouette of a furry dog. Matting tools also exist to help users with this task but they only add to the tedium of the entire editing process.  
&ensp;&ensp;An accurate pre-segmentation of the image can speed up the editing process by providing an intermediate image representation if it satisfies several criteria. First of all, such a segmentation should provide distinct segments of the image, while also representing the soft transitions between them accurately. In order to allow targeted edits, each segment should be limited to the extent of a semantically meaningful region in the image, e.g., it should not extend across the boundary between two objects. Finally, the segmentation should be done fully automatically not to add a point of interaction or require expertise from the artist. The previous approaches for semantic segmentation, image matting, or soft color segmentation fail to satisfy at least one of these qualities. In this paper, we introduce semantic soft segmentation, a fully automatic decomposition of an input image into a set of layers that cover scene objects, separated by soft transitions.  
&ensp;&ensp;We approach the semantic soft segmentation problem from a spectral decomposition angle. We combine the texture and color information from the input image together with high-level semantic cues that we generate using a convolutional neural network trained for scene analysis. We design a graph structure that reveals the semantic objects as well as the soft transitions between them in the eigenvectors of the corresponding Laplacian matrix. We introduce a spatially varying model of layer sparsity that generates high-quality layers from the eigenvectors that can be utilized for image editing.  
&ensp;&ensp;We demonstrate that our algorithm successfully decomposes images into a small number of layers that compactly and accurately represent the scene objects as shown in Figure 1. We later show that our algorithm can successfully process images that are challenging for other techniques and we provide examples of editing operations such as local color adjustment or background replacement that benefit from our layer representation.  
# 2 RELATED WORK
&ensp;&ensp;Soft segmentation. Soft segmentation is decomposing an image into two or more segments where each pixel may belong partially to more than one segment. The layer contents change depending on the specific goal of the corresponding method. For instance, soft color segmentation methods extract soft layers of homogeneous colors using global optimization [Singaraju and Vidal 2011; Tai et al. 2007; Tan et al. 2016] or per-pixel color unmixing [Aksoy et al. 2016, 2017b]. While soft color segments are shown to be useful for several image editing applications such as image recoloring, their content typically does not respect object boundaries, not allowing targeted edits. To generate spatially connected soft segments, Singaraju and Vidal [2011] start from a set of user-defined regions and solve two-layer soft segmentation problems multiple times to generate multiple layers. Levin et al. [2008b], on the other hand, propose spectral matting, estimating a set of spatially connected soft segments automatically via spectral decomposition. Both Singaraju and Vidal [2011] and Levin et al. [2008b] construct their algorithms around the matting Laplacian [Levin et al. 2008a], which provides a powerful representation for local soft transitions in the image. We also make use of the matting Laplacian and spectral decomposition, following ideas from spectral matting. However, unlike previous work, we construct a graph that fuses higher-level information coming from a deep network with the local texture information in order to generate soft segments that correspond to semantically meaningful regions in the image.  
&ensp;&ensp;Natural image matting. Natural image matting is the estimation of per-pixel opacities of a user-defined foreground region. The typical input to natural matting algorithms is a trimap, which defines the opaque foreground, the transparent background, and the unknownopacity regions. While there are different approaches to this problem all of which make use of the color characteristics of the defined foreground and background regions, the most closely-related approaches to ours are categorized as affinity-based methods. The affinity-based methods, such as closed-form matting [Levin et al. 2008a], KNN matting [Chen et al. 2013], and information-flow matting [Aksoy et al. 2017a], define inter-pixel affinities to construct a graph that reflects the opacity transitions in the image. In contrary to natural image matting methods, we rely on automatically-generated semantic features in defining our soft segments instead of a trimap, and generate multiple soft segments rather than foreground segmentation. Although they appear similar, natural matting and soft segmentation have fundamental differences. Natural matting, with a trimap as input, becomes the problem of foreground and background color modeling, may it be through selection of color samples or propagation of color information. Meanwhile, soft segmentation focuses on detecting soft transitions that best serve the target application, in our case the ones corresponding to semantic boundaries.  
&ensp;&ensp;Targeted edit propagation. Several image editing methods rely on user-defined sparse edits on the image and propagate them to the whole image. ScribbleBoost [Li et al. 2008] proposed a pipeline where they classify the objects specified by the user scribbles to allow edits targeting specific object classes in the image, and DeepProp [Endo et al. 2016] utilized a deep network to propagate class-dependent color edits. Eynard et al. [2014] constructs a graph and, parallel to our method, analyze the eigendecomposition of the corresponding Laplacian matrix to create coherent recoloring results. An and Pellacini [2008] and Chen et al. [2012] also define inter-pixel affinities and make use of the properties of the Laplacian matrices to solve for plausible propagations of the user-defined edits. While our results can also be used for targeted edits, rather than using edits defined a priori, we directly decompose the image into soft segments and let the artist use them as an intermediate image representation in various scenarios and using external image editing tools.  
&ensp;&ensp;Semantic segmentation. Semantic segmentation has improved significantly with the introduction of deep neural networks. While a detailed report on semantic segmentation is beyond our scope, state-of-the-art in semantic segmentation include works on scene parsing by Zhao et al. [2017], instance segmentation methods by He et al. [2017] and Fathi et al. [2017], and work by Bertasius et al. [2016] which enhances semantic segmentation with color boundary cues. We also make use of a deep network for semantic features, but our soft segmentation method is class-agnostic, i.e. we are interested in an accurate segmentation of the image respecting semantic boundaries, but we do not aim to do classification or detection of a selected set of classes. Others also make use of class-agnostic semantic information to improve performance in video deblurring [Ren et al. 2017] or cinemagraph generation [Oh et al. 2017].
# 3 METHOD
&ensp;&ensp;We seek to automatically generate a soft segmentation of the input image, that is, a decomposition into layers that represent the objects in the scene including transparency and soft transitions when they exist. Each pixel of each layer is augmented with an opacity value α ∈ [0, 1] with α = 0 meaning fully transparent, α = 1 fully opaque , and in-between values indicating the degree of partial opacity. As other studies in this domain such as [Aksoy et al. 2017b; Singaraju and Vidal 2011], we use an additive image formation model:{formula}, i.e., we express the input RGB pixels as the sum of the pixels in each layer i weighted by its corresponding α value. We also constrain the α values to sum up to 1 at each pixel, representing a fully opaque input image.  
&ensp;&ensp;Our approach uses the same formalism as spectral matting in formulating the soft segmentation task as an eigenvector estimation problem [Levin et al. 2008b]. The core component of this approach is the creation of a Laplacian matrix L that represents how likely each pair of pixels in the image is to belong to the same segment.  
&ensp;&ensp;While spectral matting builds this matrix using only low-level local color distributions, we describe how to augment this approach with nonlocal cues and high-level semantic information. The original approach also describes how to create the layers from the eigenvec tors of L using sparsification. We show how a relaxed version of this original technique actually yields better results. Figure 2 shows an overview of our approach.  
## 3.1 Background
&ensp;&ensp;Spectral matting. Our approach builds upon the work of Levin et al. [2008a; 2008b]. They first introduced the matting Laplacian that uses local color distributions to define a matrix L that captures the affinity between each pair of pixels in a local patch, typically 5 × 5 pixels. Using this matrix, they minimize the quadratic functional α T Lα subject to user-provided constraints, with α denoting a vector made of all the α values for a layer. This formulation shows that the eigenvectors associated to small eigenvalues of L play an important role in the creation of high-quality mattes. Motivated by this observation, their subsequent work on spectral matting used the eigenvectors of L to build a soft segmentation [Levin et al. 2008b].  
&ensp;&ensp;Each soft segment is a linear combination of the K eigenvectors corresponding to the smallest eigenvalues of L that maximizes matting sparsity, i.e., minimizes the occurrence of partial opacity. The segments are created by minimizing an energy function that favors α = 0 and α = 1:{formula}, where α ip is the α value of p th pixel of the i th segment, E is a matrix containing the K eigenvectors of L with smallest eigenvalues, y i is the linear weights on the eigenvectors that define the soft segments, and γ < 1 is a parameter that controls the strength of the sparsity prior.  
&ensp;&ensp;While spectral matting generates satisfying results when the image contains a single well-identified object with distinct colors, it struggles with more complex objects and scenes. Being based solely on the matting Laplacian that considers only low-level statistics of small patches, it is limited in its ability to identify objects. In our work, we extend this approach to fuse semantic features in the same Laplacian formulation and capture higher-level concepts like scene objects and to have a broader view of the image data.  
&ensp;&ensp;Affinity and Laplacian matrices. Levin et al. [2008a] formulate their approach as a least-squares optimization problem that directly leads to a Laplacian matrix. An alternative approach is to express the affinity between pairs of pixels [Aksoy et al. 2017a]. Pairs with a positive affinity are more likely to have similar values, zero-affinity pairs are independent, and pairs with a negative affinity are likely to have different values. In this work, we will use the affinity approach and build the corresponding normalized Laplacian matrix using the well-known formula:{formula}, where W is a square matrix containing the affinity between all pairs of pixels and D is the corresponding degree matrix, i.e. a diagonal matrix with elements W 1, 1 being a row vector of ones. As noted by Levin et al., L may not always be a true graph Laplacian due to the presence negative affinities, but nonetheless shares similar properties such as being positive semidefinite.  
